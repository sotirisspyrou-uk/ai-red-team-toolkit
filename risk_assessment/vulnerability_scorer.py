from risk_assessment import VulnerabilityScorer

# Quantify and prioritize AI security risks
vulnerability_scorer = VulnerabilityScorer()

# Configure enterprise risk assessment
risk_assessment_config = {
    'ai_systems_inventory': [
        {'name': 'customer_service_ai', 'criticality': 'high', 'exposure': 'public'},
        {'name': 'fraud_detection_ai', 'criticality': 'critical', 'exposure': 'internal'},
        {'name': 'recommendation_engine', 'criticality': 'medium', 'exposure': 'customer_facing'}
    ],
    'threat_actors': ['nation_states', 'cybercriminals', 'malicious_insiders', 'competitors'],
    'attack_scenarios': ['data_poisoning', 'model_stealing', 'adversarial_attacks'],
    'business_context': 'financial_services_regulated'
}

# Execute comprehensive risk scoring
risk_scores = vulnerability_scorer.calculate_comprehensive_risk(
    assessment_config=risk_assessment_config,
    attack_test_results=red_team_results,
    defense_test_results=blue_team_results,
    industry_benchmarks='financial_services',
    regulatory_requirements=['eu_ai_act', 'pci_dss', 'sox']
)

# Generate executive risk report
executive_report = vulnerability_scorer.generate_executive_report(
    risk_scores=risk_scores,
    business_impact_analysis=True,
    mitigation_cost_benefit=True,
    regulatory_compliance_gaps=True,
    board_presentation_ready=True
)
