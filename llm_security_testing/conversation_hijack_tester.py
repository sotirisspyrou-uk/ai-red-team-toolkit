2. LLM Security Testing Suite
Folder: llm_security_testing/

├── prompt_injection_vectors.py
├── jailbreak_attempt_generator.py
├── context_manipulation_tester.py
├── information_leakage_detector.py
├── hallucination_exploit_finder.py
├── system_prompt_extraction.py
├── conversation_hijack_tester.py
└── llm_safety_evaluator.py
Purpose: Specialized testing for Large Language Models 
Impact: Comprehensive LLM vulnerability assessment

